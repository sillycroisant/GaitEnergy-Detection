{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoàn thành tải dữ liệu lên từ C:/Users/HUY/Desktop/my_project/final_data\n",
      "Hoàn thành tải dữ liệu lên từ C:/Users/HUY/Desktop/my_project/synthetic_data\n",
      "40 20 40 20\n",
      "240 120 240 120\n"
     ]
    }
   ],
   "source": [
    "# showing image\n",
    "def show_image(image, title=\"Image\", scale=5):\n",
    "    h, w = image.shape\n",
    "    resized_image = cv2.resize(image, (w * scale, h * scale), interpolation=cv2.INTER_NEAREST)\n",
    "    cv2.imshow(title, resized_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "# load data\n",
    "\n",
    "def load_data(folder_paths, view = \"000\"):\n",
    "    train, test = [], []\n",
    "    for folder in os.listdir(folder_paths):\n",
    "        if folder == \"train\":\n",
    "            tr_labels = []\n",
    "            for img in os.listdir(f\"{folder_paths}/{folder}\"):\n",
    "                if view in img:\n",
    "                    im = np.array(cv2.imread(f\"{folder_paths}/{folder}/{img}\", cv2.IMREAD_GRAYSCALE))\n",
    "                    tr_labels.append(img[0:3])\n",
    "                    train.append(im)\n",
    "        if folder == \"test\":\n",
    "            te_labels = []\n",
    "            for img in os.listdir(f\"{folder_paths}/{folder}\"):\n",
    "                if view in img:\n",
    "                    im = np.array(cv2.imread(f\"{folder_paths}/{folder}/{img}\", cv2.IMREAD_GRAYSCALE))\n",
    "                    te_labels.append(img[0:3])\n",
    "                    test.append(im)\n",
    "    print(f\"Hoàn thành tải dữ liệu lên từ {folder_paths}\")\n",
    "    return train, test, tr_labels, te_labels\n",
    "\n",
    "final_data = \"C:/Users/HUY/Desktop/my_project/final_data\"\n",
    "synthetic_path = \"C:/Users/HUY/Desktop/my_project/synthetic_data\"          \n",
    "x_rtrain, x_rtest, y_rtrain, y_rtest = load_data(final_data, \"090\")\n",
    "x_strain, x_stest, y_strain, y_stest = load_data(synthetic_path, \"090\")\n",
    "print(len(x_rtrain), len(x_rtest), len(y_rtrain), len(y_rtest))\n",
    "print(len(x_strain), len(x_stest), len(y_strain), len(y_stest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước tập train và labels là 280 280\n",
      "Kích thước tập test và labels là 140 140\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = x_rtrain + x_strain, y_rtrain + y_strain\n",
    "x_test, y_test = x_rtest + x_stest, y_rtest + y_stest\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    match y_train[i]:\n",
    "        case '001': \n",
    "            y_train[i] = 0\n",
    "        case '002':\n",
    "            y_train[i] = 1\n",
    "        case '003':\n",
    "            y_train[i] = 2\n",
    "        case '004':\n",
    "            y_train[i] = 3\n",
    "        case '005':\n",
    "            y_train[i] = 4\n",
    "        case '006':\n",
    "            y_train[i] = 5\n",
    "        case '007':\n",
    "            y_train[i] = 6\n",
    "        case '008':\n",
    "            y_train[i] = 7\n",
    "        case '009':\n",
    "            y_train[i] = 8\n",
    "        case '010':\n",
    "            y_train[i] = 9\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    match y_test[i]:\n",
    "        case '001': \n",
    "            y_test[i] = 0\n",
    "        case '002':\n",
    "            y_test[i] = 1\n",
    "        case '003':\n",
    "            y_test[i] = 2\n",
    "        case '004':\n",
    "            y_test[i] = 3\n",
    "        case '005':\n",
    "            y_test[i] = 4\n",
    "        case '006':\n",
    "            y_test[i] = 5\n",
    "        case '007':\n",
    "            y_test[i] = 6\n",
    "        case '008':\n",
    "            y_test[i] = 7\n",
    "        case '009':\n",
    "            y_test[i] = 8\n",
    "        case '010':\n",
    "            y_test[i] = 9\n",
    "\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "print(f\"Kích thước tập train và labels là {len(x_train)} {len(y_train)}\")\n",
    "print(f\"Kích thước tập test và labels là {len(x_test)} {len(y_test)}\")\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Implement PCA manually\n",
    "# dữ liệu đưa vào PCA là dữ liệu 2 chiều (n x (64x64)) w. n = số lượng dữ liệu trong tập data\n",
    "def pca_transform(data, n_components):\n",
    "    # input\n",
    "    #   data \n",
    "    #   number of components\n",
    "    # output\n",
    "    #   the transformed data\n",
    "    #   eigen vectors \n",
    "    f_data = []\n",
    "    for i in data:\n",
    "        f_data.append(i.flatten())\n",
    "\n",
    "    mean = np.mean(f_data, axis=0)\n",
    "    centered_data = f_data - mean\n",
    "    covariance_matrix = np.cov(centered_data, rowvar=False)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices[:n_components]]\n",
    "    transformed_data = np.dot(centered_data, eigenvectors)\n",
    "    return transformed_data, eigenvectors\n",
    "\n",
    "# pca_data , pca_eigen = pca_transform(x_train, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 95 -> 31\n",
    "# 96 -> 36\n",
    "# ==> chọn số component = 32\n",
    "\n",
    "pca = PCA(n_components = 32)\n",
    "pca_data = pca.fit_transform([x.flatten() for x in x_train])\n",
    "pca_test = pca.fit_transform([x.flatten() for x in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector đặc trưng PCA:\n",
      "[-280.38842237  191.22098639 -419.34229765 -351.17232936  307.93137939\n",
      "  133.81564601  -26.76074273  215.79843571  176.24875637  326.95345706\n",
      "   25.00649876   13.83983682  219.83052316 -226.99409999   36.64503411\n",
      "  -57.76231176   94.60619952 -108.26024926   96.266322     36.60499107\n",
      "   99.81126702   40.26100878  -25.08146437 -117.09017588   -8.76261926\n",
      "   91.82293035   -7.00867712    5.15798356  -82.38126601  100.94209123\n",
      "  -32.88644431   77.44861808],\n",
      "Nhãn dán: 0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(f\"Vector đặc trưng PCA:\\n{pca_data[i]},\\nNhãn dán: {y_train[i]}\")\n",
    "\n",
    "x_train = pca_data\n",
    "x_test = pca_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mình sẽ thử với 3 mô hình khác nhau\n",
    "### Decision Tree + XGBoost\n",
    "### Mạng CNN\n",
    "### Supported Vector MachineMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 30.71%\n",
      "Accuracy: 27.14%\n",
      "Accuracy: 28.57%\n",
      "Accuracy: 27.14%\n",
      "Accuracy: 24.29%\n"
     ]
    }
   ],
   "source": [
    "# phân loại bằng RandomForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=300, \n",
    "        max_depth=20, \n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        max_features='sqrt',\n",
    "        bootstrap=True\n",
    "        )\n",
    "    rf_model.fit(x_train, y_train)\n",
    "    y_pred = rf_model.predict(pca_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 31.43%\n"
     ]
    }
   ],
   "source": [
    "# phân loại bằng XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500, \n",
    "    max_depth=16, \n",
    "    learning_rate=0.01,\n",
    "    # colsample_bytree=0.8,\n",
    "    # subsample=0.8,\n",
    "    # gamma=0.2,\n",
    "    # reg_lambda=1.0,\n",
    "    )\n",
    "xgb_model.fit(x_train, y_train)\n",
    "y_pred = xgb_model.predict(pca_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.00%\n",
      "Accuracy: 27.14%\n",
      "Accuracy: 33.57%\n",
      "Accuracy: 29.29%\n",
      "Accuracy: 28.57%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(5):\n",
    "    mlp_model = MLPClassifier(hidden_layer_sizes=(256,128), activation='logistic', max_iter=1000)\n",
    "    mlp_model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = mlp_model.predict(pca_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 10.00%\n",
      "Accuracy: 10.00%\n",
      "Accuracy: 10.00%\n",
      "Accuracy: 10.00%\n",
      "Accuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "# phân loại bằng SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "for i in range(5):\n",
    "    svm_model = SVC(C=0.01, gamma=0.1)\n",
    "    svm_model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = svm_model.predict(pca_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thử dùng RVM classifier thử xem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 32) <class 'numpy.ndarray'>\n",
      "(280,) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, type(x_train))\n",
    "print(y_train.shape, type(y_train))ss\n",
    "# data_to_save = np.hstack((x_train, y_train.reshape(-1, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. Implement MDA manually (optional)\n",
    "# def mda_transform(data, labels, n_components):\n",
    "#     data = np.array(data) if not isinstance(data, np.ndarray) else data\n",
    "#     labels = np.array(labels) if not isinstance(labels, np.ndarray) else labels\n",
    "    \n",
    "#     unique_classes = np.unique(labels)\n",
    "#     mean_total = np.mean(data, axis=0)\n",
    "#     S_b = np.zeros((data.shape[1], data.shape[1]))\n",
    "#     S_w = np.zeros((data.shape[1], data.shape[1]))\n",
    "    \n",
    "#     for cls in unique_classes:\n",
    "#         class_data = data[labels == cls]\n",
    "#         mean_class = np.mean(class_data, axis=0)\n",
    "#         S_b += len(class_data) * np.outer(mean_class - mean_total, mean_class - mean_total)\n",
    "#         S_w += np.cov(class_data, rowvar=False) * (len(class_data) - 1)\n",
    "    \n",
    "#     eigvals, eigvecs = np.linalg.eigh(np.linalg.pinv(S_w).dot(S_b))\n",
    "#     sorted_indices = np.argsort(eigvals)[::-1]\n",
    "#     eigvecs = eigvecs[:, sorted_indices[:n_components]]\n",
    "#     transformed_data = np.dot(data, eigvecs)\n",
    "#     return transformed_data, eigvecs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
