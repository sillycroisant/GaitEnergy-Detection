{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# showing image\n",
    "def show_image(image, title=\"Image\", scale=5):\n",
    "    h, w = image.shape\n",
    "    resized_image = cv2.resize(image, (w * scale, h * scale), interpolation=cv2.INTER_NEAREST)\n",
    "    cv2.imshow(title, resized_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "# load data\n",
    "data_path = \"GEI\"\n",
    "def load_data(folder_paths):\n",
    "    train, test = [], []\n",
    "    for object in os.listdir(folder_paths):\n",
    "        for type in os.listdir(f\"{folder_paths}/{object}\"):\n",
    "            for dir in os.listdir(f\"{folder_paths}/{object}/{type}\"):\n",
    "                img = cv2.imread(f\"{folder_paths}/{object}/{type}/{dir}\", cv2.IMREAD_GRAYSCALE)\n",
    "                if(object != \"010\"):\n",
    "                    train.append(img)\n",
    "                else:\n",
    "                    test.append(img)\n",
    "    \n",
    "    return train, test\n",
    "                \n",
    "real_train, real_test = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "print(len(real_train))\n",
    "print(len(real_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3920\n",
      "440\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# 3. Generate synthetic GEI templates (oke)\n",
    "def synthetic_templates(real_imgs, iter = 4, k = 2):\n",
    "    x, y = real_imgs[0].shape\n",
    "    synthetic_templates = []\n",
    "    h = 2, max(x, y)\n",
    "    \n",
    "    for img in real_imgs:\n",
    "        for i in range(1,1+iter):\n",
    "            temp = np.copy(img)\n",
    "            # remove k*i rows from the bottoms of the original img\n",
    "            temp = temp[0:x-i*k, 0:y]\n",
    "            d = math.floor(x*y/(x-i*k))\n",
    "            # resize the remaining template\n",
    "            temp = cv2.resize(temp, (d, x))\n",
    "            # equally cut left and right borders to generate a x*y size synthetic template\n",
    "            temp = temp[:,i:d-i]\n",
    "            if temp.shape[1] == 65: temp = temp[:,1:65]\n",
    "            synthetic_templates.append(temp)\n",
    "    \n",
    "    return synthetic_templates\n",
    "    \n",
    "\n",
    "synthetic_train_temp = synthetic_templates(real_train)\n",
    "synthetic_test_temp = synthetic_templates(real_test)\n",
    "print(len(synthetic_train_temp))\n",
    "print(len(synthetic_test_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Implement PCA manually\n",
    "from sklearn.decomposition import PCA   \n",
    "\n",
    "# dữ liệu đưa vào PCA là dữ liệu 2 chiều (n x (64x64)) w. n = số lượng dữ liệu trong tập data\n",
    "def pca_transform(data, n_components):\n",
    "    # input\n",
    "    #   data \n",
    "    #   number of components\n",
    "    # output\n",
    "    #   the transformed data\n",
    "    #   eigen vectors \n",
    "    f_data = []\n",
    "    for i in data:\n",
    "        f_data.append(i.flatten())\n",
    "\n",
    "    mean = np.mean(f_data, axis=0)\n",
    "    centered_data = f_data - mean\n",
    "    covariance_matrix = np.cov(centered_data, rowvar=False)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices[:n_components]]\n",
    "    transformed_data = np.dot(centered_data, eigenvectors)\n",
    "    return transformed_data, eigenvectors\n",
    "\n",
    "pca_data , pca_eigen = pca_transform(real_train, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((980, 300), (4096, 300))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_data.shape, pca_eigen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_in = []\n",
    "for d in real_train:\n",
    "    pca_in.append(d.flatten())\n",
    "    \n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "pca_data = pca.fit_transform(pca_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 47)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Implement MDA manually\n",
    "def mda_transform(data, labels, n_components):\n",
    "    data = np.array(data) if not isinstance(data, np.ndarray) else data\n",
    "    labels = np.array(labels) if not isinstance(labels, np.ndarray) else labels\n",
    "    \n",
    "    unique_classes = np.unique(labels)\n",
    "    mean_total = np.mean(data, axis=0)\n",
    "    S_b = np.zeros((data.shape[1], data.shape[1]))\n",
    "    S_w = np.zeros((data.shape[1], data.shape[1]))\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        class_data = data[labels == cls]\n",
    "        mean_class = np.mean(class_data, axis=0)\n",
    "        S_b += len(class_data) * np.outer(mean_class - mean_total, mean_class - mean_total)\n",
    "        S_w += np.cov(class_data, rowvar=False) * (len(class_data) - 1)\n",
    "    \n",
    "    eigvals, eigvecs = np.linalg.eigh(np.linalg.pinv(S_w).dot(S_b))\n",
    "    sorted_indices = np.argsort(eigvals)[::-1]\n",
    "    eigvecs = eigvecs[:, sorted_indices[:n_components]]\n",
    "    transformed_data = np.dot(data, eigvecs)\n",
    "    return transformed_data, eigvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def features_extract(real, synthetic, labels):\n",
    "    pca_features_real, pca_eigen, pca_mean = pca_transform(real, 40)\n",
    "    mda_features_real, mda_vec = mda_transform(pca_features_real, labels, 9)\n",
    "    pca_features_syn, pca_eigen_syn, pca_mean_syn = pca_transform(synthetic, 40)\n",
    "    mda_features_syn, mda_vec_syn = mda_transform(pca_features_syn, labels, 9)\n",
    "    \n",
    "    return mda_features_real, mda_features_syn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_samples = pca_data.shape[0]\n",
    "no_features = 40\n",
    "no_classes = 10\n",
    "\n",
    "dummy_data = np.random.rand(no_samples, no_features)\n",
    "\n",
    "dummy_labels = np.repeat(np.arange(no_classes), no_samples//no_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda_data, mda_eigen = mda_transform(pca_data, dummy_labels,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4900, 9)\n",
      "(40, 9)\n"
     ]
    }
   ],
   "source": [
    "print(mda_data.shape)\n",
    "print(mda_eigen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Feature extraction using PCA and MDA\n",
    "def extract_features(train_geis, labels, pca_components=30, mda_components=10):\n",
    "    pca_features, pca_eigenvectors, pca_mean = pca_transform(train_geis.reshape(len(train_geis), -1), pca_components)\n",
    "    mda_features, mda_eigenvectors = mda_transform(pca_features, labels, mda_components)\n",
    "    return mda_features, pca_eigenvectors, mda_eigenvectors, pca_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
